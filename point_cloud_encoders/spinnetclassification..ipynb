{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc4957c-2d1d-466b-aa6d-5d206528810d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30:  50%|██████████████              | 615/1230 [05:47<05:52,  1.75it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import open3d as o3d\n",
    "from torch.utils.data import DataLoader\n",
    "from learning3d.data_utils import ClassificationData, ModelNet40Data\n",
    "from SpinNet128 import Descriptor_Net\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ModelNet40 veri kümesini yükleme\n",
    "train_dataset = ClassificationData(data_class=ModelNet40Data(train=True, num_points=4096))\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
    "\n",
    "test_dataset = ClassificationData(data_class=ModelNet40Data(train=False, num_points=4096))\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
    "\n",
    "def compute_normals_single(points_single):\n",
    "    \"\"\"Tek bir nokta bulutu için Open3D ile normalleri hesaplar.\"\"\"\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points_single.astype(np.float64))\n",
    "    pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "    return np.asarray(pcd.normals)\n",
    "\n",
    "def augment(points):\n",
    "    \"\"\"Veri artırma işlemi uygular.\"\"\"\n",
    "    noise = torch.randn_like(points) * 0.03  # Gürültü ekle\n",
    "    angles = torch.rand(3) * 2 * torch.pi  # 3 eksende rastgele döndür\n",
    "    \n",
    "    Rx = torch.tensor([[1, 0, 0],\n",
    "                       [0, torch.cos(angles[0]), -torch.sin(angles[0])],\n",
    "                       [0, torch.sin(angles[0]), torch.cos(angles[0])]])\n",
    "    \n",
    "    Ry = torch.tensor([[torch.cos(angles[1]), 0, torch.sin(angles[1])],\n",
    "                       [0, 1, 0],\n",
    "                       [-torch.sin(angles[1]), 0, torch.cos(angles[1])]])\n",
    "    \n",
    "    Rz = torch.tensor([[torch.cos(angles[2]), -torch.sin(angles[2]), 0],\n",
    "                       [torch.sin(angles[2]), torch.cos(angles[2]), 0],\n",
    "                       [0, 0, 1]])\n",
    "    \n",
    "    rotation_matrix = Rz @ Ry @ Rx\n",
    "    rotation_matrix = rotation_matrix.to(points.device)\n",
    "    points = torch.matmul(points, rotation_matrix)  # Döndür\n",
    "    points = points + noise  # Gürültü ekle\n",
    "    return points\n",
    "\n",
    "class SpinNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=40, embedding_dim=128):\n",
    "        super(SpinNetClassifier, self).__init__()\n",
    "        self.encoder = self.encoder = Descriptor_Net(\n",
    "            rad_n = 9,\n",
    "            azi_n = 80,\n",
    "            ele_n = 40,\n",
    "            des_r = 0.30,\n",
    "            voxel_r = 0.04,\n",
    "            voxel_sample = 30,\n",
    "            dataset = \"3DMatch\"\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, points):\n",
    "        features = self.encoder(points)\n",
    "        global_embedding = features.squeeze()\n",
    "        logits = self.fc(global_embedding)\n",
    "        return logits\n",
    "\n",
    "# Modeli oluştur\n",
    "model = SpinNetClassifier(num_classes=40, embedding_dim=128).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.999), weight_decay=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "num_epochs = 30\n",
    "train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss, correct, total = 0, 0, 0\n",
    "    for i, data in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "        points, labels = data\n",
    "        points = (points - points.mean(dim=1, keepdim=True)) / torch.max(torch.norm(points, dim=-1, keepdim=True))\n",
    "        points = points.to(device, dtype=torch.float32)\n",
    "        labels = labels.squeeze().to(device)\n",
    "        \n",
    "        outputs = model(points)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    train_losses.append(epoch_loss / len(train_loader))\n",
    "    train_accs.append(100 * correct / total)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            points, labels = data\n",
    "            points = points.to(device, dtype=torch.float32)\n",
    "            labels = labels.squeeze().to(device)\n",
    "            \n",
    "            outputs = model(points)\n",
    "            \n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    val_losses.append(val_loss / len(test_loader))\n",
    "    val_accs.append(100 * correct / total)\n",
    "    \n",
    "    # Modeli kaydet\n",
    "    torch.save(model.encoder.state_dict(), f\"ppfnet_encoder_epoch{epoch+1}.pth\")\n",
    "    torch.save(model.fc.state_dict(), f\"ppfnet_classifier_epoch{epoch+1}.pth\")\n",
    "    scheduler.step(val_losses[-1])  # ReduceLROnPlateau kullanılıyorsa\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accs[-1]:.2f}%, Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_accs[-1]:.2f}%\")\n",
    "\n",
    "# Sonuçları görselleştir\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label='Val Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss vs. Epochs')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs + 1), train_accs, label='Train Accuracy')\n",
    "plt.plot(range(1, num_epochs + 1), val_accs, label='Val Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.title('Accuracy vs. Epochs')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eefd7f5-56df-4329-bf92-ad2297368490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Sonuçları görselleştir\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label='Val Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss vs. Epochs')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs + 1), train_accs, label='Train Accuracy')\n",
    "plt.plot(range(1, num_epochs + 1), val_accs, label='Val Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.title('Accuracy vs. Epochs')\n",
    "\n",
    "plt.savefig(\"ppfnet_train.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a823cb2-10a6-4912-8d6f-971892983242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning3d",
   "language": "python",
   "name": "learning3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
