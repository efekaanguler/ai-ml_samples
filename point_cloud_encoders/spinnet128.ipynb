{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a055435-f30b-42a8-9e5b-ffb3f0db1364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import open3d as o3d\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Learning3D kütüphanesinden PPFNet ve ChamferLoss fonksiyonu\n",
    "from learning3d.models import PPFNet\n",
    "from learning3d.losses import ChamferDistanceLoss\n",
    "from learning3d.data_utils import ModelNet40Data  # ModelNet40 veri kümesi\n",
    "from SpinNet128 import Descriptor_Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b175c68-7a99-477f-be34-0453c5024156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7edb583-4f54-4d23-932c-a00650fa86ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_normals_single(points_single):\n",
    "    \"\"\"\n",
    "    Tek bir nokta bulutu (N, 3) için Open3D kullanarak yüzey normallerini hesaplar.\n",
    "    \"\"\"\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    # Noktaların numpy array'inin tipini float64'e dönüştürüyoruz\n",
    "    pcd.points = o3d.utility.Vector3dVector(points_single.astype(np.float64))\n",
    "    pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "    normals = np.asarray(pcd.normals)\n",
    "    return normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6efdaa5-90c7-4135-8814-4f19d395e002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(points):\n",
    "    noise = torch.randn_like(points) * 0.02  # Jittering\n",
    "    angle = torch.rand(1) * 2 * torch.pi  # Random rotation\n",
    "    rotation_matrix = torch.tensor([\n",
    "        [torch.cos(angle), -torch.sin(angle), 0],\n",
    "        [torch.sin(angle), torch.cos(angle), 0],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=torch.float32).to(points.device)\n",
    "    \n",
    "    points = torch.matmul(points, rotation_matrix)  # Döndür\n",
    "    points = points + noise  # Gürültü ekle\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "902df714-8fb0-409c-a2b3-d5f71d67ef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ModelNet40Data(train=True, num_points=1024)  \n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db9e60bb-e7ea-4322-b2a7-6156e4fc6c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNetPPDecoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=128, num_points=1024):\n",
    "        super(PointNetPPDecoder, self).__init__()\n",
    "        self.num_points = num_points\n",
    "\n",
    "        # Katmanlar: Boyutları kademeli artır\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, num_points * 3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, embedding):\n",
    "        x = self.fc_layers(embedding)  # (B, num_points * 3)\n",
    "        recon = x.view(-1, self.num_points, 3)  # (B, num_points, 3)\n",
    "        return recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e79f8c3a-1f28-4d26-901d-37260872ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpinNetAutoEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=128, num_points=1024):\n",
    "        super(SpinNetAutoEncoder, self).__init__()\n",
    "        # SpinNet encoder: burada kullanılacak parametreleri isteğinize göre ayarlayın\n",
    "        self.encoder = Descriptor_Net(\n",
    "            rad_n = 9,\n",
    "            azi_n = 80,\n",
    "            ele_n = 40,\n",
    "            des_r = 0.30,\n",
    "            voxel_r = 0.04,\n",
    "            voxel_sample = 30,\n",
    "            dataset = \"3DMatch\"\n",
    "        )\n",
    "        # Basit decoder: global embedding'i alıp nokta koordinatlarını üretir.\n",
    "        self.decoder = PointNetPPDecoder(embedding_dim=128, num_points=1024)\n",
    "        \n",
    "        self.num_points = num_points\n",
    "\n",
    "    def forward(self, points):\n",
    "        # Encoder: PPFNet, points ve normals alır ve per nokta özelliklerini üretir → (B, embedding_dim, N)\n",
    "        features = self.encoder(points)\n",
    "        # Global özellik: noktalar üzerinde max pooling → (B, embedding_dim)\n",
    "        global_embedding = features.squeeze()\n",
    "        # Decoder: global embedding'i kullanarak yeniden nokta bulutu üret\n",
    "        recon = self.decoder(global_embedding)  # (B, num_points*3)\n",
    "        recon = recon.view(-1, self.num_points, 3)  # (B, num_points, 3)\n",
    "        return global_embedding, recon\n",
    "\n",
    "# Modeli oluştur ve cihaza taşı\n",
    "model = SpinNetAutoEncoder(embedding_dim=128, num_points=1024).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "507945c5-8597-4e1d-9b84-defb9da2817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = ChamferDistanceLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=15, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2877e59-9572-4238-b30a-f26284687848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|███████████████████████████| 1230/1230 [07:46<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 0.1239, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|███████████████████████████| 1230/1230 [07:34<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/15], Loss: 0.1127, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|███████████████████████████| 1230/1230 [07:35<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/15], Loss: 0.1089, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|███████████████████████████| 1230/1230 [07:48<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/15], Loss: 0.1091, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|███████████████████████████| 1230/1230 [07:44<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/15], Loss: 0.1073, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100%|███████████████████████████| 1230/1230 [07:34<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/15], Loss: 0.1063, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100%|███████████████████████████| 1230/1230 [05:22<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/15], Loss: 0.1061, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: 100%|███████████████████████████| 1230/1230 [03:36<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/15], Loss: 0.1074, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: 100%|███████████████████████████| 1230/1230 [03:42<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/15], Loss: 0.1059, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: 100%|██████████████████████████| 1230/1230 [03:43<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/15], Loss: 0.1059, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: 100%|██████████████████████████| 1230/1230 [03:43<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/15], Loss: 0.1059, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15:  15%|████                       | 184/1230 [00:34<03:13,  5.40it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     24\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     27\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/learning3d/lib/python3.10/site-packages/torch/nn/utils/clip_grad.py:69\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_if_nonfinite \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlogical_or(total_norm\u001b[38;5;241m.\u001b[39misnan(), total_norm\u001b[38;5;241m.\u001b[39misinf()):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe total norm of order \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnorm_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for gradients from \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`parameters` is non-finite, so it cannot be clipped. To disable \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthis error and scale the gradients by the non-finite norm anyway, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset `error_if_nonfinite=False`\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m clip_coef \u001b[38;5;241m=\u001b[39m \u001b[43mmax_norm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_norm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Note: multiplying by the clamped coef is redundant when the coef is clamped to 1, but doing so\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# avoids a `if clip_coef < 1:` conditional which can require a CPU <=> device synchronization\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# when the gradients do not reside in CPU memory.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m clip_coef_clamped \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(clip_coef, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[0;32m~/learning3d/lib/python3.10/site-packages/torch/_tensor.py:38\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f, assigned\u001b[38;5;241m=\u001b[39massigned)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;66;03m# See https://github.com/pytorch/pytorch/issues/75462\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mhas_torch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "        # Veri kümesinden noktaları al; etiketler bu autoencoder için kullanılmayacak.\n",
    "        points, _ = data  # Sadece nokta bulutu verisi\n",
    "        points = points - points.mean(dim=1, keepdim=True)  # Merkezi sıfıra getir\n",
    "        points = points / torch.max(torch.norm(points, dim=-1, keepdim=True))  # Birime normalize et\n",
    "        points = augment(points)\n",
    "\n",
    "        points = points.to(device, dtype=torch.float32)\n",
    "        \n",
    "        # İleri geçiş\n",
    "        embedding, recon_points = model(points)\n",
    "        \n",
    "        # Kayıp hesaplama: Yeniden oluşturulan nokta bulutu ile orijinal arasındaki chamfer distance\n",
    "        loss = criterion(recon_points, points) + 0.01 * torch.norm(embedding, p=2)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss / len(train_loader):.4f}, LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "print(\"Eğitim tamamlandı!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f34cb1a1-0a84-42f0-b2d4-7bf01c3b6758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder modelini kaydet\n",
    "torch.save(model.decoder.state_dict(), \"spinnet128_decoder.pth\")\n",
    "\n",
    "# Sadece Encoder kısmını kaydet\n",
    "torch.save(model.encoder.state_dict(), \"spinnet128_encoder.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738009d1-327f-4932-ae1f-80a189dcbb73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning3d",
   "language": "python",
   "name": "learning3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
