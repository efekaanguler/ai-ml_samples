{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "935c7d65-db0a-4343-bae9-afd20651aaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 309/309 [03:14<00:00,  1.59it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, fowlkes_mallows_score, silhouette_score\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import open3d as o3d\n",
    "from torch.utils.data import DataLoader\n",
    "from learning3d.models import PPFNet\n",
    "from learning3d.data_utils import ClassificationData, ModelNet40Data\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Cihaz ayarı\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Test veri kümesini yükleme\n",
    "test_dataset = ClassificationData(data_class=ModelNet40Data(train=False, num_points=4096))\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
    "\n",
    "# Modeli oluştur ve ağırlıkları yükle\n",
    "class PPFNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=40, embedding_dim=128):\n",
    "        super(PPFNetClassifier, self).__init__()\n",
    "        self.encoder = PPFNet(features=['ppf', 'dxyz', 'xyz'], emb_dims=embedding_dim, radius=0.3, num_neighbors=64)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, points, normals):\n",
    "        features = self.encoder(points, normals)\n",
    "        global_embedding = torch.max(features, dim=1)[0]\n",
    "        return self.fc(global_embedding)\n",
    "\n",
    "model = PPFNetClassifier(num_classes=40, embedding_dim=128).to(device)\n",
    "model.encoder.load_state_dict(torch.load(\"ppfnet_encoder_epoch25.pth\", map_location=device))\n",
    "model.fc.load_state_dict(torch.load(\"ppfnet_classifier_epoch25.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Normal hesaplama fonksiyonu\n",
    "def compute_normals_single(points_single):\n",
    "    \"\"\"Open3D kullanarak yüzey normallerini hesaplar.\"\"\"\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points_single.astype(np.float64))\n",
    "    pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "    return np.asarray(pcd.normals)  \n",
    "\n",
    "def random_rotation_single_axis(points, max_angle):\n",
    "    \"\"\"Belirli bir eksende rastgele dönüşüm uygular.\"\"\"\n",
    "    axis = random.choice([0, 1, 2])  # Rastgele bir eksen seç\n",
    "    angle = random.uniform(-max_angle, max_angle)  # Rastgele dönüş açısı belirle\n",
    "    \n",
    "    rotation_matrix = torch.eye(3)  # 3x3 birim matris\n",
    "    c, s = torch.cos(torch.tensor(angle)), torch.sin(torch.tensor(angle))\n",
    "    \n",
    "    if axis == 0:  # X ekseni dönüşü\n",
    "        rotation_matrix[1, 1] = c\n",
    "        rotation_matrix[1, 2] = -s\n",
    "        rotation_matrix[2, 1] = s\n",
    "        rotation_matrix[2, 2] = c\n",
    "    elif axis == 1:  # Y ekseni dönüşü\n",
    "        rotation_matrix[0, 0] = c\n",
    "        rotation_matrix[0, 2] = s\n",
    "        rotation_matrix[2, 0] = -s\n",
    "        rotation_matrix[2, 2] = c\n",
    "    else:  # Z ekseni dönüşü\n",
    "        rotation_matrix[0, 0] = c\n",
    "        rotation_matrix[0, 1] = -s\n",
    "        rotation_matrix[1, 0] = s\n",
    "        rotation_matrix[1, 1] = c\n",
    "\n",
    "    return torch.matmul(points, rotation_matrix.to(points.device))  # Dönüşümü uygula\n",
    "\n",
    "\n",
    "def random_rotation(points, max_angle):\n",
    "    \"\"\"Rastgele dönüşüm uygular.\"\"\"\n",
    "    angles = torch.empty(3).uniform_(-max_angle, max_angle)  # Her eksen için rastgele açı seç\n",
    "    Rx = torch.tensor([\n",
    "        [1, 0, 0],\n",
    "        [0, torch.cos(angles[0]), -torch.sin(angles[0])],\n",
    "        [0, torch.sin(angles[0]), torch.cos(angles[0])]\n",
    "    ])\n",
    "    Ry = torch.tensor([\n",
    "        [torch.cos(angles[1]), 0, torch.sin(angles[1])],\n",
    "        [0, 1, 0],\n",
    "        [-torch.sin(angles[1]), 0, torch.cos(angles[1])]\n",
    "    ])\n",
    "    Rz = torch.tensor([\n",
    "        [torch.cos(angles[2]), -torch.sin(angles[2]), 0],\n",
    "        [torch.sin(angles[2]), torch.cos(angles[2]), 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    rotation_matrix = torch.matmul(Rz, torch.matmul(Ry, Rx))  # Döndürme matrisini oluştur\n",
    "    return torch.matmul(points, rotation_matrix.to(points.device))  # Dönüşümü uygula \n",
    "\n",
    "\n",
    "def evaluate_clustering():\n",
    "    \"\"\"Orijinal ve dönüşümlü objeler için kümeleme skorlarını hesaplar.\"\"\"\n",
    "    scores = {\n",
    "        \"Original\": [],\n",
    "        \"Single Small\": [],\n",
    "        \"All Small\": [],\n",
    "        \"Single Large\": [],\n",
    "        \"All Large\": [],\n",
    "    }\n",
    "\n",
    "    all_labels, original_encs, enc_1s, enc_2s, enc_3s, enc_4s = [], [], [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for points, labels in tqdm(test_loader):\n",
    "            points = points.to(device)\n",
    "\n",
    "            # 4 Farklı Dönüşüm\n",
    "            rotated_1 = random_rotation_single_axis(points, torch.pi / 18)  # Single Small (~10°)\n",
    "            rotated_2 = random_rotation(points, torch.pi / 18)  # All Small (~10°)\n",
    "            rotated_3 = random_rotation_single_axis(points, torch.pi / 3)   # Single Large (~60°)\n",
    "            rotated_4 = random_rotation(points, torch.pi / 3)   # All Large (~60°)\n",
    "\n",
    "            # Normalize\n",
    "            normals = torch.tensor(np.stack([compute_normals_single(p.cpu().numpy()) for p in points.cpu()], axis=0), dtype=torch.float32).to(device)\n",
    "            normals_1 = torch.tensor(np.stack([compute_normals_single(p.cpu().numpy()) for p in rotated_1.cpu()], axis=0), dtype=torch.float32).to(device)\n",
    "            normals_2 = torch.tensor(np.stack([compute_normals_single(p.cpu().numpy()) for p in rotated_2.cpu()], axis=0), dtype=torch.float32).to(device)\n",
    "            normals_3 = torch.tensor(np.stack([compute_normals_single(p.cpu().numpy()) for p in rotated_3.cpu()], axis=0), dtype=torch.float32).to(device)\n",
    "            normals_4 = torch.tensor(np.stack([compute_normals_single(p.cpu().numpy()) for p in rotated_4.cpu()], axis=0), dtype=torch.float32).to(device)\n",
    "\n",
    "            # **Encoder Çıktıları**\n",
    "            original_encoding = model.encoder(points, normals)\n",
    "            original_encoding, _ = torch.max(original_encoding, dim=1)\n",
    "            original_encoding = original_encoding.cpu().numpy().astype(np.float16)\n",
    "            enc_1 = model.encoder(rotated_1, normals_1)\n",
    "            enc_1 = torch.max(enc_1, dim=1)[0]\n",
    "            enc_1 = enc_1.cpu().numpy().astype(np.float16)\n",
    "            enc_2 = model.encoder(rotated_2, normals_2)\n",
    "            enc_2 = torch.max(enc_2, dim=1)[0]\n",
    "            enc_2 = enc_2.cpu().numpy().astype(np.float16)\n",
    "            enc_3 = model.encoder(rotated_3, normals_3)\n",
    "            enc_3 = torch.max(enc_3, dim=1)[0]\n",
    "            enc_3 = enc_3.cpu().numpy().astype(np.float16)\n",
    "            enc_4 = model.encoder(rotated_4, normals_4)\n",
    "            enc_4 = torch.max(enc_4, dim=1)[0]\n",
    "            enc_4 = enc_4.cpu().numpy().astype(np.float16)\n",
    "\n",
    "            original_encs.extend(original_encoding)\n",
    "            enc_1s.extend(enc_1)\n",
    "            enc_2s.extend(enc_2)\n",
    "            enc_3s.extend(enc_3)\n",
    "            enc_4s.extend(enc_4)\n",
    "            all_labels.extend(labels.cpu().numpy().astype(np.float16))\n",
    "    all_encs = [original_encs, enc_1s, enc_2s, enc_3s, enc_4s]\n",
    "\n",
    "    return all_encs, all_labels, scores\n",
    "\n",
    "all_encs, all_labels, scores = evaluate_clustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52faba2e-4dfa-4b33-8ae7-f51c8f89423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(all_encs, all_labels, scores):\n",
    "    # **Clustering Performansını Ölç**\n",
    "    for key, encs in zip(scores.keys(), all_encs):\n",
    "        \n",
    "        ari, nmi, fmi, silhouette = clustering_performance(encs, all_labels)\n",
    "        scores[key] = [ari, nmi, fmi, silhouette]\n",
    "\n",
    "    # **Sonuçları Yazdır**\n",
    "    print(\"\\n==== Kümeleme Performans Sonuçları ====\")\n",
    "    for key, values in scores.items():\n",
    "        print(f\"{key}: ARI={values[0]:.4f}, NMI={values[1]:.4f}, FMI={values[2]:.4f}, Silhouette={values[3]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a592dbaa-7542-4f9e-803f-2ba970ffcbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_performance(encodings, true_labels):\n",
    "    \"\"\"Kümeleme algoritması ile 40 cluster'a ayır ve performansı değerlendir.\"\"\"\n",
    "    kmeans = KMeans(n_clusters=40, random_state=42, n_init=\"auto\")  \n",
    "    predicted_clusters = kmeans.fit_predict(encodings)\n",
    "    true_labels = np.squeeze(true_labels, axis=-1)\n",
    "\n",
    "    ari = adjusted_rand_score(true_labels, predicted_clusters)  \n",
    "    nmi = normalized_mutual_info_score(true_labels, predicted_clusters)  \n",
    "    fmi = fowlkes_mallows_score(true_labels, predicted_clusters)  \n",
    "    silhouette = silhouette_score(encodings, predicted_clusters)\n",
    "\n",
    "    return ari, nmi, fmi, silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2add10a2-91cd-4b00-bb97-89ab0cc3a973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Kümeleme Performans Sonuçları ====\n",
      "Original: ARI=0.5260, NMI=0.7318, FMI=0.5424, Silhouette=0.1576\n",
      "Single Small: ARI=0.5626, NMI=0.7434, FMI=0.5780, Silhouette=0.1384\n",
      "All Small: ARI=0.5152, NMI=0.7099, FMI=0.5318, Silhouette=0.1190\n",
      "Single Large: ARI=0.2523, NMI=0.4946, FMI=0.2779, Silhouette=0.0881\n",
      "All Large: ARI=0.0882, NMI=0.3184, FMI=0.1181, Silhouette=0.0459\n"
     ]
    }
   ],
   "source": [
    "evaluate(all_encs, all_labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e1effb-a9fc-4eb8-bbd9-99024ea21d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning3d",
   "language": "python",
   "name": "learning3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
