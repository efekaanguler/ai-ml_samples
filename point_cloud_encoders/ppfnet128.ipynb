{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "584e1c55-3990-4921-84da-9c51fa1004dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import open3d as o3d\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Learning3D kütüphanesinden PPFNet ve ChamferLoss fonksiyonu\n",
    "from learning3d.models import PPFNet\n",
    "from learning3d.losses import ChamferDistanceLoss\n",
    "from learning3d.data_utils import ModelNet40Data  # ModelNet40 veri kümesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55ffcb53-ce4c-4a42-98fd-92af05d58e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e47d0cc0-2270-4fe7-8ca2-d3345a70a28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_normals_single(points_single):\n",
    "    \"\"\"\n",
    "    Tek bir nokta bulutu (N, 3) için Open3D kullanarak yüzey normallerini hesaplar.\n",
    "    \"\"\"\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    # Noktaların numpy array'inin tipini float64'e dönüştürüyoruz\n",
    "    pcd.points = o3d.utility.Vector3dVector(points_single.astype(np.float64))\n",
    "    pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "    normals = np.asarray(pcd.normals)\n",
    "    return normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16892d0b-2017-4423-9e86-d7263dff4bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(points):\n",
    "    noise = torch.randn_like(points) * 0.02  # Jittering\n",
    "    angle = torch.rand(1) * 2 * torch.pi  # Random rotation\n",
    "    rotation_matrix = torch.tensor([\n",
    "        [torch.cos(angle), -torch.sin(angle), 0],\n",
    "        [torch.sin(angle), torch.cos(angle), 0],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=torch.float32).to(points.device)\n",
    "    \n",
    "    points = torch.matmul(points, rotation_matrix)  # Döndür\n",
    "    points = points + noise  # Gürültü ekle\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "755a1955-e61e-41ee-b779-19233c1b0759",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ModelNet40Data(train=True, num_points=1024)  \n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34e32e23-0707-42a6-829a-637dd9d5ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNetPPDecoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=128, num_points=1024):\n",
    "        super(PointNetPPDecoder, self).__init__()\n",
    "        self.num_points = num_points\n",
    "\n",
    "        # Katmanlar: Boyutları kademeli artır\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, num_points * 3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, embedding):\n",
    "        x = self.fc_layers(embedding)  # (B, num_points * 3)\n",
    "        recon = x.view(-1, self.num_points, 3)  # (B, num_points, 3)\n",
    "        return recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd4ee55d-0119-499f-bbbe-676587614076",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPFNetAutoEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=128, num_points=1024):\n",
    "        super(PPFNetAutoEncoder, self).__init__()\n",
    "        # PPFNet encoder: burada kullanılacak parametreleri isteğinize göre ayarlayın\n",
    "        self.encoder = PPFNet(features=['ppf', 'dxyz', 'xyz'], emb_dims=embedding_dim, radius=0.3, num_neighbors=64)\n",
    "        # Basit decoder: global embedding'i alıp nokta koordinatlarını üretir.\n",
    "        self.decoder = PointNetPPDecoder(embedding_dim=128, num_points=1024)\n",
    "    \n",
    "        self.num_points = num_points\n",
    "    \n",
    "    def forward(self, points, normals):\n",
    "        # Encoder: PPFNet, points ve normals alır ve per nokta özelliklerini üretir → (B, embedding_dim, N)\n",
    "        features = self.encoder(points, normals)\n",
    "        # Global özellik: noktalar üzerinde max pooling → (B, embedding_dim)\n",
    "        global_embedding = torch.max(features, dim=1)[0]\n",
    "        # Decoder: global embedding'i kullanarak yeniden nokta bulutu üret\n",
    "        recon = self.decoder(global_embedding)  # (B, num_points*3)\n",
    "        recon = recon.view(-1, self.num_points, 3)  # (B, num_points, 3)\n",
    "        return global_embedding, recon\n",
    "\n",
    "# Modeli oluştur ve cihaza taşı\n",
    "model = PPFNetAutoEncoder(embedding_dim=128, num_points=1024).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74deeeb5-8195-4e83-b848-2fe4002b7962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPFNet(\n",
      "  (prepool): Sequential(\n",
      "    (0): Conv2d(10, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (4): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (7): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
      "    (8): ReLU()\n",
      "  )\n",
      "  (postpool): Sequential(\n",
      "    (0): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "    (1): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
      "    (4): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "    (5): ReLU()\n",
      "    (6): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55e7bf8b-d44a-4eef-a643-ad984fcc2a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = ChamferDistanceLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf3f48a7-219e-4a92-9dff-5878dce68071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|███████████████████████████| 1230/1230 [02:36<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.0995, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|███████████████████████████| 1230/1230 [02:36<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30], Loss: 0.0837, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|███████████████████████████| 1230/1230 [02:38<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30], Loss: 0.0806, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|███████████████████████████| 1230/1230 [02:43<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30], Loss: 0.0792, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|███████████████████████████| 1230/1230 [02:36<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30], Loss: 0.0764, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|███████████████████████████| 1230/1230 [02:35<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30], Loss: 0.0710, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|███████████████████████████| 1230/1230 [02:36<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/30], Loss: 0.0667, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|███████████████████████████| 1230/1230 [02:34<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/30], Loss: 0.0649, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|███████████████████████████| 1230/1230 [02:34<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/30], Loss: 0.0639, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████████████████████| 1230/1230 [02:35<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30], Loss: 0.0633, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████████████████████| 1230/1230 [02:35<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/30], Loss: 0.0629, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████████████████████| 1230/1230 [02:35<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30], Loss: 0.0621, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████████████████████| 1230/1230 [02:35<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/30], Loss: 0.0613, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████████████████████| 1230/1230 [02:35<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/30], Loss: 0.0605, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████████████████████| 1230/1230 [02:35<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/30], Loss: 0.0597, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████████████████████| 1230/1230 [02:36<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/30], Loss: 0.0590, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████████████████████| 1230/1230 [02:43<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/30], Loss: 0.0582, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████████████████████| 1230/1230 [02:37<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/30], Loss: 0.0574, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████████████████████| 1230/1230 [02:35<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30], Loss: 0.0566, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|██████████████████████████| 1230/1230 [02:35<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/30], Loss: 0.0560, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|██████████████████████████| 1230/1230 [02:34<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/30], Loss: 0.0551, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|██████████████████████████| 1230/1230 [02:34<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/30], Loss: 0.0544, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|██████████████████████████| 1230/1230 [02:34<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/30], Loss: 0.0539, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|██████████████████████████| 1230/1230 [02:34<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/30], Loss: 0.0534, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|██████████████████████████| 1230/1230 [02:33<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/30], Loss: 0.0528, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|██████████████████████████| 1230/1230 [02:33<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/30], Loss: 0.0524, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|██████████████████████████| 1230/1230 [02:33<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/30], Loss: 0.0521, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|██████████████████████████| 1230/1230 [02:33<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/30], Loss: 0.0518, LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|██████████████████████████| 1230/1230 [02:33<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/30], Loss: 0.0514, LR: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: 100%|██████████████████████████| 1230/1230 [02:34<00:00,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/30], Loss: 0.0511, LR: 0.001000\n",
      "Eğitim tamamlandı!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "        # Veri kümesinden noktaları al; etiketler bu autoencoder için kullanılmayacak.\n",
    "        points, _ = data  # Sadece nokta bulutu verisi\n",
    "        points = points - points.mean(dim=1, keepdim=True)  # Merkezi sıfıra getir\n",
    "        points = points / torch.max(torch.norm(points, dim=-1, keepdim=True))  # Birime normalize et\n",
    "        points = augment(points)\n",
    "        \n",
    "        points = points.to(device, dtype=torch.float32)\n",
    "        \n",
    "        # Batch içindeki her örnek için normalleri hesaplayın.\n",
    "        points_np = points.cpu().numpy()  # Şekil: (B, N, 3)\n",
    "        normals_list = []\n",
    "        for pc in points_np:\n",
    "            normals_pc = compute_normals_single(pc)  # Her pc: (N, 3)\n",
    "            normals_list.append(normals_pc)\n",
    "        normals_np = np.stack(normals_list, axis=0)  # (B, N, 3)\n",
    "        normals = torch.tensor(normals_np, dtype=torch.float32).to(device)\n",
    "        \n",
    "        # İleri geçiş\n",
    "        embedding, recon_points = model(points, normals)\n",
    "        \n",
    "        # Kayıp hesaplama: Yeniden oluşturulan nokta bulutu ile orijinal arasındaki chamfer distance\n",
    "        loss = criterion(recon_points, points) + 0.01 * torch.norm(embedding, p=2)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss / len(train_loader):.4f}, LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "print(\"Eğitim tamamlandı!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44bd6a8e-1b79-4fd8-ba57-98b8adaa943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder modelini kaydet\n",
    "torch.save(model.decoder.state_dict(), \"ppfnet128_decoder.pth\")\n",
    "\n",
    "# Sadece Encoder kısmını kaydet\n",
    "torch.save(model.encoder.state_dict(), \"ppfnet128_encoder.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c27120-673d-47a4-9376-6717bf0a0a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning3d",
   "language": "python",
   "name": "learning3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
